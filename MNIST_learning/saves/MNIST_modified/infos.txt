Neural network.
Size of Number: 4 bytes
Input size: 784
Number of layers: 4
Layer 째1 -> number of neurons: 512, activation: ReLu
Layer 째2 -> number of neurons: 64, activation: ReLu
Layer 째3 -> number of neurons: 32, activation: ReLu
Layer 째4 -> number of neurons: 11, activation: Sigmoid
